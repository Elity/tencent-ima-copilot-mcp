"""
IMA API å®¢æˆ·ç«¯å®ç°
"""
import asyncio
import base64
import codecs
import json
import random
import re
import secrets
import string
import time
import traceback
import uuid
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, AsyncGenerator, Dict, List, Optional
from urllib.parse import unquote

import aiohttp
from loguru import logger
from tenacity import (
    AsyncRetrying,
    RetryError,
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from models import (
    IMAConfig,
    IMAMessage,
    MessageType,
    KnowledgeBaseMessage,
    TextMessage,
    MediaInfo,
    DeviceInfo,
    IMAStatus,
    TokenRefreshRequest,
    TokenRefreshResponse,
    InitSessionRequest,
    InitSessionResponse,
    EnvInfo,
    KnowledgeBaseInfoWithFolder,
    AskQuestionRequest, # New
    CommandInfo, # New
    KnowledgeQaInfo, # New
    ModelInfo, # New
    HistoryInfo, # New
)




class IMAAPIClient:
    """IMA API å®¢æˆ·ç«¯"""

    def __init__(self, config: IMAConfig):
        self.config = config
        self.base_url = "https://ima.qq.com"
        self.api_endpoint = "/cgi-bin/assistant/qa"
        self.refresh_endpoint = "/cgi-bin/auth_login/refresh"
        self.init_session_endpoint = "/cgi-bin/session_logic/init_session"
        self.session: Optional[aiohttp.ClientSession] = None
        self.raw_log_dir: Optional[Path] = None
        self._token_lock = asyncio.Lock()  # ä¿æŠ¤ token åˆ·æ–°è¿‡ç¨‹

        if getattr(self.config, "enable_raw_logging", False):
            raw_dir_value = getattr(self.config, "raw_log_dir", None)
            raw_dir = Path(raw_dir_value) if raw_dir_value else Path("logs") / "sse_raw"
            try:
                raw_dir.mkdir(parents=True, exist_ok=True)
                self.raw_log_dir = raw_dir
                logger.info(f"Raw SSE logs will be written to: {raw_dir}")
            except Exception as exc:
                logger.error(f"Failed to prepare raw SSE log directory: {exc}")

    def _should_persist_raw(self, stream_error: Optional[str]) -> bool:
        """åˆ¤æ–­å½“å‰æ˜¯å¦éœ€è¦ä¿å­˜åŸå§‹SSEå“åº”"""
        if not self.raw_log_dir or not getattr(self.config, "enable_raw_logging", False):
            return False

        if stream_error:
            return True  # always persist on errors

        return getattr(self.config, "raw_log_on_success", False)

    def _persist_raw_response(
        self,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
        full_response: str,
        message_count: int,
        parsed_message_count: int,
        failed_parse_count: int,
        elapsed_time: float,
        stream_error: Optional[str],
    ) -> Optional[Path]:
        """å°†åŸå§‹SSEå“åº”è½ç›˜ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜"""
        if not self._should_persist_raw(stream_error):
            return None

        assert self.raw_log_dir is not None  # for type checkers

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        suffix = f"attempt{attempt_index + 1}"
        filename = f"sse_{timestamp}_{trace_id}_{suffix}.log"
        target_path = self.raw_log_dir / filename

        max_bytes = getattr(self.config, "raw_log_max_bytes", 0) or 0
        encoded = full_response.encode("utf-8", errors="replace")
        response_bytes = len(encoded)
        truncated = False

        if max_bytes > 0 and response_bytes > max_bytes:
            encoded = encoded[:max_bytes]
            truncated = True

        preview_question = None
        if question:
            preview_question = question.strip()
            if len(preview_question) > 200:
                preview_question = preview_question[:200] + "..."

        metadata = {
            "timestamp": datetime.now().isoformat(),
            "trace_id": trace_id,
            "attempt": attempt_index + 1,
            "question": preview_question,
            "message_count": message_count,
            "parsed_message_count": parsed_message_count,
            "failed_parse_count": failed_parse_count,
            "elapsed_seconds": round(elapsed_time, 3),
            "response_bytes": response_bytes,
            "truncated": truncated,
            "stream_error": stream_error,
        }

        try:
            header = json.dumps(metadata, ensure_ascii=False, indent=2)
            body = encoded.decode("utf-8", errors="replace")

            with target_path.open("w", encoding="utf-8") as fp:
                fp.write(header)
                fp.write("\n\n")
                fp.write(body)

            logger.info(f"Raw SSE response saved to {target_path} (trace_id={trace_id})")
            return target_path
        except Exception as exc:
            logger.error(f"Failed to persist raw SSE response: {exc}")
            return None

    def _is_token_expired(self) -> bool:
        """æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ"""
        if not self.config.token_updated_at or not self.config.token_valid_time:
            return True
        
        expired_time = self.config.token_updated_at + timedelta(seconds=self.config.token_valid_time)
        # æå‰ 5 åˆ†é’Ÿåˆ·æ–°ä»¥é˜²ä¸‡ä¸€
        return datetime.now() > (expired_time - timedelta(minutes=5))

    def _parse_user_id_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-UID"""
        try:
            uid_pattern = r"IMA-UID=([^;]+)"
            match = re.search(uid_pattern, self.config.x_ima_cookie)
            if match:
                return match.group(1)

            user_id_pattern = r"user_id=([a-f0-9]{16})"
            if self.config.cookies:
                match = re.search(user_id_pattern, self.config.cookies)
                if match:
                    return match.group(1)
        except Exception as e:
            logger.warning(f"è§£æuser_idå¤±è´¥: {e}")
        return None

    def _parse_refresh_token_from_cookies(self) -> Optional[str]:
        """ä»IMA_X_IMA_COOKIEä¸­è§£æIMA-REFRESH-TOKEN"""
        try:
            refresh_token_pattern = r"IMA-REFRESH-TOKEN=([^;]+)"
            match = re.search(refresh_token_pattern, self.config.x_ima_cookie)
            if match:
                token = unquote(match.group(1))
                logger.info(f"æˆåŠŸä» x_ima_cookie è§£æ IMA-REFRESH-TOKEN (é•¿åº¦: {len(token)})")
                return token
            
            logger.warning("åœ¨ x_ima_cookie ä¸­æœªæ‰¾åˆ° IMA-REFRESH-TOKEN")
            
            token_pattern = r"IMA-TOKEN=([^;]+)"
            match = re.search(token_pattern, self.config.x_ima_cookie)
            if match:
                token = unquote(match.group(1))
                logger.warning(f"ä½¿ç”¨ IMA-TOKEN ä½œä¸º refresh_tokenï¼ˆé•¿åº¦: {len(token)}ï¼‰")
                return token

            if self.config.cookies:
                refresh_token_pattern = r"refresh_token=([^;]+)"
                match = re.search(refresh_token_pattern, self.config.cookies)
                if match:
                    token = unquote(match.group(1))
                    logger.info(f"æˆåŠŸä» cookies è§£æ refresh_token")
                    return token
            
            logger.warning("æœªèƒ½ä»ä»»ä½•æ¥æºè§£æåˆ° refresh_token")
        except Exception as e:
            logger.error(f"è§£æ refresh_token å¤±è´¥: {e}\n{traceback.format_exc()}")
        return None

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError)),
        before_sleep=before_sleep_log(logger, "WARNING"),
        reraise=True
    )
    async def refresh_token(self) -> bool:
        """åˆ·æ–°è®¿é—®ä»¤ç‰Œ"""
        async with self._token_lock:
            # åŒé‡æ£€æŸ¥
            if not self._is_token_expired() and self.config.current_token:
                return True

            logger.info("ğŸ”„ å¼€å§‹åˆ·æ–° Token")
            
            if not self.config.user_id or not self.config.refresh_token:
                logger.info("ä» cookies ä¸­è§£æ user_id å’Œ refresh_token")
                self.config.user_id = self._parse_user_id_from_cookies()
                self.config.refresh_token = self._parse_refresh_token_from_cookies()

                if not self.config.user_id or not self.config.refresh_token:
                    logger.warning("ç¼ºå°‘tokenåˆ·æ–°æ‰€éœ€çš„user_idæˆ–refresh_token")
                    return False

            try:
                session = await self._get_session()

                # æ„å»ºåˆ·æ–°è¯·æ±‚
                refresh_request = TokenRefreshRequest(
                    user_id=self.config.user_id,
                    refresh_token=self.config.refresh_token
                )

                refresh_url = f"{self.base_url}{self.refresh_endpoint}"
                
                # æ„å»ºè¯·æ±‚å¤´ - ä¸ä½¿ç”¨ _build_headers ä»¥é¿å…å‘é€è¿‡æœŸçš„ token
                refresh_headers = {
                    "accept": "application/json",
                    "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
                    "content-type": "application/json",
                    "from_browser_ima": "1",
                    "x-ima-cookie": self.config.x_ima_cookie,
                    "x-ima-bkn": self.config.x_ima_bkn,
                    "referer": "https://ima.qq.com/wikis",
                    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
                }
                
                request_body = refresh_request.model_dump()

                async with session.post(
                    refresh_url,
                    json=request_body,
                    headers=refresh_headers
                ) as response:
                    response_text = await response.text()
                    if response.status == 200:
                        try:
                            response_data = await response.json()
                            refresh_response = TokenRefreshResponse(**response_data)

                            if refresh_response.code == 0 and refresh_response.token:
                                # æ›´æ–°tokenä¿¡æ¯
                                self.config.current_token = refresh_response.token
                                self.config.token_valid_time = int(refresh_response.token_valid_time or "7200")
                                self.config.token_updated_at = datetime.now()

                                logger.info(f"âœ… Tokenåˆ·æ–°æˆåŠŸ (æœ‰æ•ˆæœŸ: {self.config.token_valid_time}ç§’)")
                                return True
                            else:
                                logger.warning("=" * 60)
                                logger.warning(f"Tokenåˆ·æ–°å¤±è´¥: {refresh_response.msg} (Code: {refresh_response.code})")
                                logger.warning("=" * 60)
                                return False
                        except json.JSONDecodeError as je:
                            logger.error(f"æ— æ³•è§£æå“åº”ä¸º JSON: {je}")
                            logger.error(f"åŸå§‹å“åº”: {response_text[:200]}")
                            return False
                    else:
                        logger.error(f"Tokenåˆ·æ–°è¯·æ±‚å¤±è´¥: HTTP {response.status}")
                        return False

            except Exception as e:
                logger.error(f"Tokenåˆ·æ–°å¼‚å¸¸: {type(e).__name__}: {e}")
                return False

    async def ensure_valid_token(self) -> bool:
        """ç¡®ä¿tokenæœ‰æ•ˆï¼Œå¦‚æœè¿‡æœŸåˆ™åˆ·æ–°"""
        if self._is_token_expired():
            return await self.refresh_token()
        return True

    
    def _parse_cookies(self, cookie_string: str) -> Dict[str, str]:
        """è§£æ Cookie å­—ç¬¦ä¸²ä¸ºå­—å…¸"""
        cookies = {}
        if not cookie_string:
            return cookies

        # å¤„ç†ä¸åŒæ ¼å¼çš„ Cookie å­—ç¬¦ä¸²
        cookie_parts = cookie_string.split(';')
        for part in cookie_parts:
            if '=' in part:
                name, value = part.strip().split('=', 1)
                cookies[name.strip()] = value.strip()
        return cookies

    def _build_headers(self, for_init_session: bool = False) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        x_ima_cookie = self.config.x_ima_cookie
        
        # å¦‚æœæœ‰æ–°çš„ tokenï¼ŒåŠ¨æ€æ›¿æ¢åˆ° Cookie ä¸­
        if self.config.current_token:
            if 'IMA-TOKEN=' in x_ima_cookie:
                x_ima_cookie = re.sub(
                    r'IMA-TOKEN=[^;]+',
                    f'IMA-TOKEN={self.config.current_token}',
                    x_ima_cookie
                )
            else:
                x_ima_cookie = x_ima_cookie.rstrip('; ') + f'; IMA-TOKEN={self.config.current_token}'
        
        headers = {
            "x-ima-cookie": x_ima_cookie,
            "from_browser_ima": "1",
            "extension_version": "999.999.999",
            "x-ima-bkn": self.config.x_ima_bkn,
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "accept": "application/json" if for_init_session else "*/*",
            "content-type": "application/json" if for_init_session else "text/event-stream",
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6",
            "referer": "https://ima.qq.com/wikis",
        }

        if self.config.current_token:
            headers["authorization"] = f"Bearer {self.config.current_token}"
        
        return headers

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=5),
        retry=retry_if_exception_type((aiohttp.ClientError, OSError)),
        before_sleep=before_sleep_log(logger, "WARNING"),
        reraise=True
    )
    async def _get_session(self) -> aiohttp.ClientSession:
        """è·å–æˆ–åˆ›å»º HTTP ä¼šè¯"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=30,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=60,
            )

            sse_timeout = 600  # å¢åŠ æ€»è¶…æ—¶åˆ° 10 åˆ†é’Ÿä»¥æ”¯æŒæé•¿å›å¤
            
            timeout = aiohttp.ClientTimeout(
                total=sse_timeout,
                sock_read=180,
                connect=30,
                sock_connect=30,
            )
            
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                cookies=self._parse_cookies(self.config.cookies or ""),
                # æ³¨æ„ï¼šä¸åœ¨ session å±‚é¢å›ºå®š headersï¼Œå› ä¸º token å¯èƒ½ä¼šå˜
                trust_env=True,
                read_bufsize=5 * 2**20,
                auto_decompress=True,
            )

        return self.session

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯ä¼šè¯"""
        if self.session and not self.session.closed:
            await self.session.close()

    def _generate_session_id(self) -> str:
        """ç”Ÿæˆä¼šè¯ ID"""
        return ''.join(random.choices(string.ascii_lowercase + string.digits, k=24))

    def _generate_temp_uskey(self) -> str:
        """ç”Ÿæˆä¸´æ—¶ uskey"""
        return base64.b64encode(secrets.token_bytes(32)).decode('utf-8')

    def _build_request(self, question: str, session_id: str) -> AskQuestionRequest:
        """æ„å»º IMA API è¯·æ±‚"""
        uskey = self._generate_temp_uskey()

        try:
            ima_guid = self.config.x_ima_cookie.split('IMA-GUID=')[1].split(';')[0]
        except (IndexError, AttributeError):
            ima_guid = "default_guid"

        device_info = DeviceInfo(
            uskey=uskey,
            uskey_bus_infos_input=f"{ima_guid}_{int(datetime.now().timestamp())}"
        )

        return AskQuestionRequest(
            session_id=session_id,
            robot_type=self.config.robot_type,
            question=question,
            question_type=2,
            client_id=self.config.client_id,
            command_info=CommandInfo(
                type=14,
                knowledge_qa_info=KnowledgeQaInfo(
                    tags=[],
                    knowledge_ids=[]
                )
            ),
            model_info=ModelInfo(
                model_type=self.config.model_type,
                enable_enhancement=False
            ),
            history_info=HistoryInfo(),
            device_info=device_info
        )

    def _parse_sse_message(self, line: str) -> Optional[IMAMessage]:
        """è§£æ SSE æ¶ˆæ¯"""
        try:
            if line.startswith('data: '):
                data = line[6:]
            elif line.startswith(('event: ', 'id: ')):
                return None
            else:
                data = line

            if not data or data == '[DONE]' or not data.strip():
                return None

            json_data = json.loads(data)

            if 'msgs' in json_data and isinstance(json_data['msgs'], list):
                for msg in json_data['msgs']:
                    if isinstance(msg, dict) and 'content' in msg:
                        content = msg.get('content', '')
                        if content:
                            return TextMessage(
                                type=MessageType.TEXT,
                                content=content,
                                text=content,
                                raw=data
                            )
                return None

            if 'content' in json_data:
                content = json_data['content']
                if isinstance(content, str) and content:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=content,
                        text=content,
                        raw=data
                    )

            if 'Text' in json_data and isinstance(json_data['Text'], str):
                return TextMessage(
                    type=MessageType.TEXT,
                    content=json_data['Text'],
                    text=json_data['Text'],
                    raw=data
                )

            if 'type' in json_data and json_data['type'] == 'knowledgeBase':
                if 'content' not in json_data:
                    json_data['content'] = json_data.get('processing', 'çŸ¥è¯†åº“æœç´¢ä¸­...')
                return KnowledgeBaseMessage(**json_data)

            if 'question' in json_data and 'answer' in json_data:
                answer = json_data.get('answer', '')
                if answer:
                    return TextMessage(
                        type=MessageType.TEXT,
                        content=answer,
                        text=answer,
                        raw=data
                    )

            return IMAMessage(
                type=MessageType.SYSTEM,
                content=str(json_data),
                raw=data
            )

        except (json.JSONDecodeError, KeyError, ValueError):
            raise

    async def _process_sse_stream(
        self,
        response: aiohttp.ClientResponse,
        *,
        trace_id: str,
        attempt_index: int,
        question: Optional[str],
    ) -> AsyncGenerator[IMAMessage, None]:
        """å¤„ç† SSE æµ"""
        buffer = ""
        full_response = ""
        message_count = 0
        parsed_message_count = 0
        failed_parse_count = 0
        initial_timeout = 180
        chunk_timeout = 120
        last_data_time = asyncio.get_event_loop().time()
        start_time = asyncio.get_event_loop().time()
        has_received_data = False
        sample_chunks = []
        stream_error: Optional[str] = None
        
        # ä½¿ç”¨å¢é‡è§£ç å™¨å¤„ç†å¯èƒ½è¢«æˆªæ–­çš„å¤šå­—èŠ‚å­—ç¬¦
        decoder = codecs.getincrementaldecoder("utf-8")(errors="replace")

        try:
            logger.debug(f"ğŸ”„ [SSEæµ] å¼€å§‹è¯»å– (trace_id={trace_id})")
            logger.debug(f"  æ‰‹åŠ¨è¶…æ—¶é…ç½®: initial={initial_timeout}s, chunk={chunk_timeout}s")
            
            async for chunk in response.content:
                current_time = asyncio.get_event_loop().time()

                timeout_threshold = chunk_timeout if has_received_data else initial_timeout
                elapsed_since_last_data = current_time - last_data_time
                
                # æ‰‹åŠ¨è¶…æ—¶æ£€æŸ¥ï¼ˆé€šå¸¸ä¸ä¼šè§¦å‘ï¼Œå› ä¸ºaiohttpçš„timeoutä¼šå…ˆè§¦å‘ï¼‰
                if elapsed_since_last_data > timeout_threshold:
                    stream_error = f"Manual timeout after {elapsed_since_last_data:.1f}s with {message_count} chunks"
                    logger.warning(f"â° [SSEæµ] æ‰‹åŠ¨è¶…æ—¶è§¦å‘: {stream_error}")
                    break

                if chunk:
                    has_received_data = True
                    last_data_time = current_time
                    message_count += 1

                    # ä½¿ç”¨å¢é‡è§£ç å™¨è§£ç 
                    chunk_str = decoder.decode(chunk, final=False)

                    buffer += chunk_str
                    full_response += chunk_str

                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        if line:
                            try:
                                message = self._parse_sse_message(line)
                                if message:
                                    parsed_message_count += 1
                                    yield message
                            except (json.JSONDecodeError, KeyError, ValueError):
                                failed_parse_count += 1


        except asyncio.TimeoutError:
            if has_received_data and parsed_message_count > 0:
                stream_error = None
            else:
                stream_error = "SSE timeout"
                logger.error(f"âŒ [SSEæµ] è¶…æ—¶é”™è¯¯ï¼ˆæœªæ”¶åˆ°æ•°æ®ï¼‰, trace_id={trace_id}")
        except aiohttp.ClientPayloadError as exc:
            stream_error = f"SSE payload error: {exc}"
            logger.error(f"âŒ [SSEæµ] ClientPayloadError: {exc}, trace_id={trace_id}")
        except Exception as exc:
            stream_error = f"SSE exception: {exc}"
            logger.error(f"âŒ [SSEæµ] æœªçŸ¥å¼‚å¸¸: {type(exc).__name__}: {exc}, trace_id={trace_id}\n{traceback.format_exc()}")
        finally:
            # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­
            if not response.closed:
                response.close()
            
            # åˆ·æ–°è§£ç å™¨ä¸­å‰©ä½™çš„å­—èŠ‚
            remaining_str = decoder.decode(b"", final=True)
            if remaining_str:
                buffer += remaining_str
                full_response += remaining_str

            elapsed_time = asyncio.get_event_loop().time() - start_time
            self._persist_raw_response(
                trace_id=trace_id,
                attempt_index=attempt_index,
                question=question,
                full_response=full_response,
                message_count=message_count,
                parsed_message_count=parsed_message_count,
                failed_parse_count=failed_parse_count,
                elapsed_time=elapsed_time,
                stream_error=stream_error,
            )

        # å¤„ç†å‰©ä½™çš„ç¼“å†²åŒºå†…å®¹
        if buffer.strip():
            remaining_lines = buffer.strip().split('\n')
            for i, line in enumerate(remaining_lines):
                line = line.strip()
                if line:
                    try:
                        message = self._parse_sse_message(line)
                        if message:
                            parsed_message_count += 1
                            yield message
                    except (json.JSONDecodeError, KeyError, ValueError):
                        failed_parse_count += 1

        if message_count < 100 or not has_received_data:
            try:
                if full_response.strip():
                    response_data = json.loads(full_response.strip())
                    messages = self._extract_messages_from_response(response_data)
                    for message in messages:
                        yield message

            except json.JSONDecodeError:
                if full_response:
                    lines = full_response.split('\n')
                    for i, line in enumerate(lines):
                        line = line.strip()
                        if line and line != '[DONE]':
                            message = self._parse_sse_message(line)
                            if message:
                                parsed_message_count += 1
                                yield message
                            else:
                                failed_parse_count += 1

        elapsed_time = asyncio.get_event_loop().time() - start_time
        
        logger.info("=" * 80)
        logger.info(f"âœ… [SSEæµ] å¤„ç†å®Œæˆ (trace_id={trace_id})")
        logger.info(f"  æ”¶åˆ°æ•°æ®å—: {message_count} ä¸ª, æˆåŠŸè§£æ: {parsed_message_count} æ¡, å¤±è´¥: {failed_parse_count} æ¬¡")
        logger.info(f"  å“åº”å¤§å°: {len(full_response)} å­—èŠ‚, è€—æ—¶: {elapsed_time:.1f} ç§’")
        
        if stream_error:
            logger.warning(f"  âš ï¸ æµé”™è¯¯: {stream_error}")
        
        # è¯Šæ–­ä¿¡æ¯ï¼šå¦‚æœè€—æ—¶æ¥è¿‘30ç§’ï¼Œå¾ˆå¯èƒ½æ˜¯aiohttpçš„total timeoutè§¦å‘
        if 29.0 <= elapsed_time <= 31.0:
            logger.warning(f"  âš ï¸ [è¯Šæ–­] è€—æ—¶æ­£å¥½çº¦30ç§’ï¼Œæ€€ç–‘æ˜¯aiohttpçš„ClientTimeout.totalè§¦å‘")
            logger.warning(f"  âš ï¸ [è¯Šæ–­] å»ºè®®æ£€æŸ¥ IMAConfig.timeout é…ç½®å€¼ï¼ˆå½“å‰: {getattr(self.config, 'timeout', 'N/A')}sï¼‰")
            logger.warning(f"  âš ï¸ [è¯Šæ–­] å¯¹äºé•¿æ—¶é—´SSEæµï¼Œå»ºè®®å°†timeoutè®¾ç½®ä¸º300ç§’ä»¥ä¸Š")
        
        logger.info("=" * 80)

        if message_count > 100 and parsed_message_count < 5:
            logger.error(f"ä¸¥é‡: æ”¶åˆ° {message_count} ä¸ªchunkä½†åªè§£æå‡º {parsed_message_count} æ¡æ¶ˆæ¯ï¼Œ"
                        f"è§£æç‡ {(parsed_message_count/message_count*100):.1f}%")
            logger.debug(f"å‰10ä¸ªchunkæ ·æœ¬: {sample_chunks}")

    def _extract_messages_from_response(self, response_data: Dict[str, Any]) -> List[IMAMessage]:
        """ä»å®Œæ•´å“åº”ä¸­æå–æ¶ˆæ¯"""
        messages = []

        try:
            if 'msgs' in response_data and isinstance(response_data['msgs'], list):
                msgs_list = response_data['msgs']
                if msgs_list:
                    last_msg = msgs_list[-1]
                    if isinstance(last_msg, dict):
                        if last_msg.get('type') == 3:
                            qa_content = last_msg.get('content', {})
                            if isinstance(qa_content, dict):
                                answer = qa_content.get('answer', '')
                                if isinstance(answer, str) and answer:
                                    try:
                                        answer_data = json.loads(answer)
                                        if isinstance(answer_data, dict) and 'Text' in answer_data:
                                            text_content = answer_data['Text']
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=text_content,
                                                text=text_content,
                                                raw=str(last_msg)
                                            ))
                                        else:
                                            messages.append(TextMessage(
                                                type=MessageType.TEXT,
                                                content=answer,
                                                text=answer,
                                                raw=str(last_msg)
                                            ))
                                    except json.JSONDecodeError:
                                        messages.append(TextMessage(
                                            type=MessageType.TEXT,
                                            content=answer,
                                            text=answer,
                                            raw=str(last_msg)
                                        ))

                                context_refs = qa_content.get('context_refs', '')
                                if context_refs:
                                    try:
                                        context_data = json.loads(context_refs)
                                        if isinstance(context_data, dict):
                                            # è§£æ medias å¹¶åˆ›å»º KnowledgeBaseMessage
                                            medias_list = []
                                            if 'medias' in context_data and isinstance(context_data['medias'], list):
                                                for media_data in context_data['medias']:
                                                    try:
                                                        # å°è¯•è½¬æ¢ä¸º MediaInfo å¯¹è±¡
                                                        media_info = MediaInfo(**media_data)
                                                        medias_list.append(media_info)
                                                    except Exception as e:
                                                        logger.warning(f"Failed to parse media info: {e}")

                                            if medias_list:
                                                messages.append(KnowledgeBaseMessage(
                                                    type=MessageType.KNOWLEDGE_BASE,
                                                    content="å‚è€ƒèµ„æ–™",
                                                    medias=medias_list,
                                                    raw=context_refs
                                                ))
                                    except json.JSONDecodeError:
                                        logger.warning(f"Failed to decode context_refs: {context_refs[:100]}...")

            logger.info(f"ä»å“åº”ä¸­æå–äº† {len(messages)} æ¡æ¶ˆæ¯")
            return messages

        except Exception as e:
            logger.error(f"æå–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            messages.append(IMAMessage(
                type=MessageType.SYSTEM,
                content=str(response_data),
                raw=str(response_data)
            ))
            return messages

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError)),
        before_sleep=before_sleep_log(logger, "WARNING"),
        reraise=True
    )
    async def init_session(self, knowledge_base_id: Optional[str] = None) -> str:
        """åˆå§‹åŒ–ä¼šè¯å¹¶è¿”å› session_id"""
        kb_id = knowledge_base_id or getattr(self.config, 'knowledge_base_id', '7305806844290061')

        logger.info(f"ğŸ”„ åˆå§‹åŒ–ä¼šè¯ (çŸ¥è¯†åº“: {kb_id})")
        if not await self.ensure_valid_token():
            logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
            raise ValueError("Authentication failed - unable to obtain valid token")
        
        session = await self._get_session()

        init_request = InitSessionRequest(
            envInfo=EnvInfo(
                robotType=5,
                interactType=0
            ),
            relatedUrl=kb_id,
            sceneType=1,
            msgsLimit=10,
            forbidAutoAddToHistoryList=False,
            knowledgeBaseInfoWithFolder=KnowledgeBaseInfoWithFolder(
                knowledge_base_id=kb_id,
                folder_ids=[]
            )
        )
        
        url = f"{self.base_url}{self.init_session_endpoint}"
        request_json = init_request.model_dump(by_alias=True, exclude_none=True)
        headers = self._build_headers(for_init_session=True)

        try:
            async with session.post(
                url,
                json=request_json,
                headers=headers
            ) as response:
                if response.status != 200:
                    response_text = await response.text()
                    logger.error(f"åˆå§‹åŒ–ä¼šè¯å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status}")
                    raise ValueError(f"init_session HTTPé”™è¯¯ {response.status}: {response_text[:500]}")
                
                response_data = await response.json()
                init_response = InitSessionResponse(**response_data)

                if init_response.code == 0 and init_response.session_id:
                    logger.info(f"âœ… ä¼šè¯åˆå§‹åŒ–æˆåŠŸ (session_id: {init_response.session_id[:16]}...)")
                    return init_response.session_id
                else:
                    logger.error(f"âŒ ä¼šè¯åˆå§‹åŒ–å¤±è´¥ (code: {init_response.code}): {init_response.msg}")
                    raise ValueError(f"Session initialization failed (code: {init_response.code}): {init_response.msg}")

        except Exception as e:
            logger.error(f"ä¼šè¯åˆå§‹åŒ–å¼‚å¸¸: {e}")
            raise

    async def ask_question(self, question: str, session_id: Optional[str] = None) -> AsyncGenerator[IMAMessage, None]:
        """å‘ IMA è¯¢é—®é—®é¢˜ (æ”¯æŒæµå¼è¿”å›)"""
        if not question.strip():
            raise ValueError("Question cannot be empty")

        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not await self.ensure_valid_token():
            raise ValueError("Authentication failed - unable to obtain valid token")

        # å¦‚æœæ²¡æœ‰æä¾› session_idï¼Œåˆ™åŠ¨æ€åˆå§‹åŒ–ä¸€ä¸ªæ–°ä¼šè¯ï¼ˆå®ç°æ— çŠ¶æ€/å•æ¬¡å¯¹è¯éš”ç¦»ï¼‰
        if not session_id:
            logger.debug("ğŸ”„ æœªæä¾› session_idï¼Œåˆå§‹åŒ–ä¸´æ—¶ä¼šè¯...")
            session_id = await self.init_session()

        session = await self._get_session()
        request_data = self._build_request(question, session_id)
        url = f"{self.base_url}{self.api_endpoint}"
        headers = self._build_headers(for_init_session=False)

        # ç”Ÿæˆtrace_idç”¨äºè·Ÿè¸ª
        trace_id = str(uuid.uuid4())[:8]

        with logger.contextualize(trace_id=trace_id):
            logger.debug("å‘é€é—®é¢˜", question_preview=question[:50])

            response = None
            try:
                response = await session.post(
                    url,
                    json=request_data.model_dump(),
                    headers=headers
                )

                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status != 200:
                    response_text = await response.text()
                    logger.error("HTTPè¯·æ±‚å¤±è´¥", status=response.status, response=response_text[:500])
                    raise ValueError(f"HTTP {response.status}: {response_text[:200]}")

                content_type = response.headers.get('content-type', '')
                if 'text/event-stream' not in content_type:
                    response_text = await response.text()
                    try:
                        error_data = json.loads(response_text)
                        raise ValueError(f"APIé”™è¯¯ (code: {error_data.get('code')}): {error_data.get('msg')}")
                    except json.JSONDecodeError:
                        raise ValueError(f"æ„å¤–å“åº”ç±»å‹: {content_type}, å†…å®¹: {response_text[:200]}")

                # å¤„ç†æµå¼å“åº”
                message_count = 0
                async for message in self._process_sse_stream(
                    response,
                    trace_id=trace_id,
                    attempt_index=0,
                    question=question
                ):
                    message_count += 1
                    yield message

                if message_count == 0:
                    yield IMAMessage(type=MessageType.SYSTEM, content="æœªæ”¶åˆ°æœ‰æ•ˆå“åº”", raw="No SSE messages")

            finally:
                if response and not response.closed:
                    response.close()

    def _is_login_expired_error(self, error_str: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯ç™»å½•è¿‡æœŸç›¸å…³é”™è¯¯"""
        login_expired_patterns = [
            "Session initialization failed",
            "ç™»å½•è¿‡æœŸ", "ç™»å½•å¤±è´¥", "authentication failed", "è®¤è¯å¤±è´¥",
            "code: 600001", "code: 600002", "code: 600003",
            "token expired", "ä¼šè¯å·²è¿‡æœŸ", "è¯·é‡æ–°ç™»å½•", "unauthorized", "401"
        ]
        error_lower = error_str.lower()
        return any(pattern.lower() in error_lower for pattern in login_expired_patterns)

    async def ask_question_complete(self, question: str, timeout: Optional[float] = None) -> List[IMAMessage]:
        """è·å–å®Œæ•´çš„é—®é¢˜å›ç­” - æ”¯æŒè‡ªåŠ¨é‡è¯•"""
        start_time = time.time()

        async def _attempt_request():
            if timeout and (time.time() - start_time > timeout):
                raise asyncio.TimeoutError("Total timeout exceeded")

            messages = []
            # æ¯æ¬¡å°è¯•ä½¿ç”¨æ–°çš„ session_id ä»¥ç¡®ä¿éš”ç¦»
            session_id = await self.init_session()
            
            gen = self.ask_question(question, session_id=session_id)
            try:
                async for msg in gen:
                    messages.append(msg)
                    if timeout and (time.time() - start_time > timeout):
                        break
            finally:
                await gen.aclose()
            
            if not messages:
                raise ValueError("æœªæ”¶åˆ°æœ‰æ•ˆæ¶ˆæ¯")
            return messages

        try:
            retryer = AsyncRetrying(
                stop=stop_after_attempt(self.config.retry_count + 1),
                wait=wait_exponential(multiplier=1, min=1, max=10),
                retry=retry_if_exception_type((aiohttp.ClientError, asyncio.TimeoutError, ValueError)),
                before_sleep=before_sleep_log(logger, "WARNING"),
                reraise=True
            )
            
            async for attempt in retryer:
                with attempt:
                    try:
                        return await _attempt_request()
                    except ValueError as e:
                        if self._is_login_expired_error(str(e)):
                            logger.info("æ£€æµ‹åˆ°ç™»å½•å¤±æ•ˆï¼Œå¼ºåˆ¶åˆ·æ–° Token å¹¶é‡è¯•...")
                            await self.refresh_token()
                        raise

        except Exception as e:
            logger.exception("é—®ç­”å¤±è´¥", question_preview=question[:50])
            return [IMAMessage(type=MessageType.SYSTEM, content=f"è¯·æ±‚å¤±è´¥: {e}", raw=str(e))]

    def _extract_text_content(self, messages: List[IMAMessage]) -> str:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–æ–‡æœ¬å†…å®¹ - ä»…æå–æ–‡æœ¬ç±»å‹çš„æ¶ˆæ¯"""
        if not messages:
            return "æ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”"

        content_parts = []

        for message in messages:
            # ä»…æå– TextMessage ä¸”ç±»å‹ä¸º TEXT çš„å†…å®¹
            if message.type == MessageType.TEXT:
                if isinstance(message, TextMessage) and message.text:
                    content_parts.append(message.text)
                elif hasattr(message, 'content') and message.content:
                    content_parts.append(message.content)

        # æ‹¼æ¥æ‰€æœ‰å†…å®¹
        final_result = ''.join(content_parts).strip()

        # æ¸…ç†å’Œæ ¼å¼åŒ–ç»“æœ
        final_result = self._clean_response_content(final_result)

        logger.debug(f"æœ€ç»ˆå“åº”å†…å®¹é•¿åº¦: {len(final_result)}")
        return final_result

    def _clean_response_content(self, content: str) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–å“åº”å†…å®¹"""
        if not content:
            return content

        # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
        lines = content.split('\n')
        cleaned_lines = []
        prev_empty = False

        for line in lines:
            line = line.strip()
            if line:
                cleaned_lines.append(line)
                prev_empty = False
            elif not prev_empty:
                cleaned_lines.append('')
                prev_empty = True

        return '\n'.join(cleaned_lines)

    
    def _extract_knowledge_info(self, messages: List[IMAMessage]) -> List[Dict[str, Any]]:
        """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–çŸ¥è¯†åº“ä¿¡æ¯"""
        knowledge_items = []

        for message in messages:
            if isinstance(message, KnowledgeBaseMessage) and message.medias:
                for media in message.medias:
                    knowledge_items.append({
                        'id': media.id,
                        'title': media.title,
                        'subtitle': media.subtitle,
                        'introduction': media.introduction,
                        'timestamp': media.timestamp,
                        'knowledge_base': media.knowledge_base_info.name if media.knowledge_base_info else None
                    })

        return knowledge_items



  
